#!/usr/bin/env python3
"""
Final System Validation Report
Comprehensive test of the hybrid architecture implementation.
"""

import sys
import os
import asyncio
import json
from datetime import datetime
from typing import Dict, Any, List

# Configure path
sys.path.append('/Users/cpconnor/projects/Meld and RAG')

def create_validation_report() -> Dict[str, Any]:
    """Create a comprehensive validation report."""
    report = {
        "validation_timestamp": datetime.now().isoformat(),
        "system_name": "Hybrid VectorDBRAG + MindMeld Architecture",
        "version": "1.0",
        "tests": {},
        "summary": {},
        "recommendations": []
    }
    
    # Test 1: Shared Framework
    print("üß™ Testing Shared Framework...")
    try:
        from shared_agents.core.agent_factory import AgentFactory, AgentCapability, AgentBase, AgentResponse
        from shared_agents.config.shared_config import SharedConfig, ConfigManager
        
        report["tests"]["shared_framework"] = {
            "status": "PASS",
            "details": "All core shared framework components imported successfully",
            "capabilities": [cap.value for cap in AgentCapability],
            "capability_count": len(AgentCapability)
        }
        print("‚úÖ Shared framework: PASS")
    except Exception as e:
        report["tests"]["shared_framework"] = {
            "status": "FAIL",
            "error": str(e)
        }
        print(f"‚ùå Shared framework: FAIL ({e})")
    
    # Test 2: Enhanced Agent Factory
    print("üß™ Testing Enhanced Agent Factory...")
    try:
        from VectorDBRAG.agents.enhanced.factory import EnhancedAgentFactory
        
        config = {
            'model': 'gpt-3.5-turbo',
            'default_model': 'gpt-3.5-turbo',
            'openai_client': None
        }
        
        factory = EnhancedAgentFactory(config)
        agent_types = factory.get_agent_types()
        
        # Test agent creation
        test_agent = factory.create_agent('code_analysis', 'ValidationTestAgent')
        
        report["tests"]["enhanced_factory"] = {
            "status": "PASS",
            "details": "Enhanced agent factory created and functional",
            "agent_types": list(agent_types.keys()),
            "agent_count": len(agent_types),
            "test_agent_created": True,
            "test_agent_name": test_agent.name,
            "test_agent_capabilities": [cap.value for cap in test_agent.capabilities]
        }
        print("‚úÖ Enhanced agent factory: PASS")
    except Exception as e:
        report["tests"]["enhanced_factory"] = {
            "status": "FAIL",
            "error": str(e)
        }
        print(f"‚ùå Enhanced agent factory: FAIL ({e})")
    
    # Test 3: Capability-Based Agent Creation
    print("üß™ Testing Capability-Based Agent Creation...")
    try:
        debug_agents = factory.create_agents_with_capability(AgentCapability.CODE_DEBUGGING)
        repair_agents = factory.create_agents_with_capability(AgentCapability.CODE_REPAIR)
        analysis_agents = factory.create_agents_with_capability(AgentCapability.CODE_ANALYSIS)
        
        report["tests"]["capability_creation"] = {
            "status": "PASS",
            "details": "Capability-based agent creation working",
            "debug_agents": len(debug_agents),
            "repair_agents": len(repair_agents),
            "analysis_agents": len(analysis_agents),
            "total_capability_matches": len(debug_agents) + len(repair_agents) + len(analysis_agents)
        }
        print("‚úÖ Capability-based creation: PASS")
    except Exception as e:
        report["tests"]["capability_creation"] = {
            "status": "FAIL",
            "error": str(e)
        }
        print(f"‚ùå Capability-based creation: FAIL ({e})")
    
    # Test 4: Ollama Integration
    print("üß™ Testing Ollama Integration...")
    try:
        from VectorDBRAG.agents_ollama import OLLAMA_AVAILABLE, CodeAnalyzerAgent
        
        if OLLAMA_AVAILABLE:
            ollama_agent = CodeAnalyzerAgent(name="ValidationOllamaAgent", model="phi3.5")
            ollama_status = "AVAILABLE"
            ollama_details = f"Ollama agent created: {ollama_agent.name}"
        else:
            ollama_status = "UNAVAILABLE"
            ollama_details = "Ollama client not connected"
        
        report["tests"]["ollama_integration"] = {
            "status": ollama_status,
            "details": ollama_details,
            "ollama_available": OLLAMA_AVAILABLE
        }
        print(f"‚úÖ Ollama integration: {ollama_status}")
    except Exception as e:
        report["tests"]["ollama_integration"] = {
            "status": "ERROR",
            "error": str(e)
        }
        print(f"‚ö†Ô∏è  Ollama integration: ERROR ({e})")
    
    # Test 5: Environment Configuration
    print("üß™ Testing Environment Configuration...")
    env_tests = {
        "openai_api_key": bool(os.getenv("OPENAI_API_KEY")),
        "ollama_host": os.getenv("OLLAMA_HOST", "http://localhost:11434"),
        "local_model": os.getenv("LOCAL_MODEL", "phi3.5"),
        "python_path_configured": '/Users/cpconnor/projects/Meld and RAG' in sys.path
    }
    
    report["tests"]["environment"] = {
        "status": "PASS",
        "details": "Environment configuration checked",
        **env_tests
    }
    print("‚úÖ Environment configuration: PASS")
    
    # Test 6: Project Structure
    print("üß™ Testing Project Structure...")
    required_paths = [
        '/Users/cpconnor/projects/Meld and RAG/shared_agents',
        '/Users/cpconnor/projects/Meld and RAG/VectorDBRAG',
        '/Users/cpconnor/projects/Meld and RAG/MindMeld-v1.1',
        '/Users/cpconnor/projects/Meld and RAG/shared_agents/core',
        '/Users/cpconnor/projects/Meld and RAG/VectorDBRAG/agents/enhanced'
    ]
    
    structure_status = all(os.path.exists(path) for path in required_paths)
    
    report["tests"]["project_structure"] = {
        "status": "PASS" if structure_status else "FAIL",
        "details": "Project structure validation",
        "required_paths": required_paths,
        "all_paths_exist": structure_status
    }
    print(f"‚úÖ Project structure: {'PASS' if structure_status else 'FAIL'}")
    
    # Generate Summary
    passed_tests = sum(1 for test in report["tests"].values() 
                      if test.get("status") in ["PASS", "AVAILABLE"])
    total_tests = len(report["tests"])
    
    report["summary"] = {
        "total_tests": total_tests,
        "passed_tests": passed_tests,
        "success_rate": f"{(passed_tests/total_tests)*100:.1f}%",
        "overall_status": "HEALTHY" if passed_tests >= total_tests - 1 else "NEEDS_ATTENTION"
    }
    
    # Generate Recommendations
    if not env_tests["openai_api_key"]:
        report["recommendations"].append("Set OPENAI_API_KEY environment variable for full functionality")
    
    if report["tests"]["ollama_integration"]["status"] != "AVAILABLE":
        report["recommendations"].append("Install and start Ollama for local model support")
    
    if passed_tests == total_tests:
        report["recommendations"].append("System is fully operational and ready for production")
    
    return report

def main():
    """Run the complete validation and generate report."""
    print("üöÄ Final System Validation")
    print("=" * 50)
    print("Hybrid VectorDBRAG + MindMeld Architecture")
    print("=" * 50)
    
    try:
        report = create_validation_report()
        
        # Print summary
        print("\nüìä Validation Summary")
        print("=" * 30)
        print(f"Total Tests: {report['summary']['total_tests']}")
        print(f"Passed Tests: {report['summary']['passed_tests']}")
        print(f"Success Rate: {report['summary']['success_rate']}")
        print(f"Overall Status: {report['summary']['overall_status']}")
        
        # Print recommendations
        if report["recommendations"]:
            print("\nüí° Recommendations")
            print("=" * 20)
            for i, rec in enumerate(report["recommendations"], 1):
                print(f"{i}. {rec}")
        
        # Save detailed report
        report_file = "/Users/cpconnor/projects/Meld and RAG/FINAL_VALIDATION_REPORT.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\nüìÑ Detailed report saved to: {report_file}")
        
        # Final status
        if report['summary']['overall_status'] == 'HEALTHY':
            print("\nüéâ VALIDATION COMPLETE: System is fully operational!")
            print("‚úÖ Hybrid architecture successfully implemented")
            print("‚úÖ Enhanced agents working with shared framework")
            print("‚úÖ Ready for production deployment")
        else:
            print("\n‚ö†Ô∏è  VALIDATION COMPLETE: System needs attention")
            print("üîß Review recommendations above")
        
        return report['summary']['overall_status'] == 'HEALTHY'
        
    except Exception as e:
        print(f"\n‚ùå Validation failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
